\documentclass{report}

\usepackage{natbib} 
\usepackage{lipsum}
\usepackage{url}
\usepackage{hyperref}
\usepackage{minted}
\usepackage{graphicx}

\begin{document}

\title{LibrumCI: Leveraging Container Cluster Management Framework Natives in continuous integration}

\numberofauthors{1}\author{
\alignauthor
Anthony Troy\\
       \affaddr{School of Computing}\\
       \affaddr{Dublin City University}\\
       \affaddr{Dublin 9, Ireland}\\
       \email{\\anthony.troy3@mail.dcu.ie}
}

\date{22 August 2016}

\maketitle

\begin{abstract}
Continuous integration practices seek to reduce software deployment lead time
through ensuring that team members are frequently integrating work that is 
verified by automated builds and tests in production-like environments. 
Effective continuous integration pipelines must be capable of automatically
provisioning such environments for testing upon team members contributing any
infrastructural or environmental changes. Similarly,
robust continuous integration infrastructures must be capable of such
automated provisioning to decrease build execution load. VM-based environments
struggle to efficiently support such workflows due the challenges and limitations 
around the automated provisioning and configuration management of virtual machines.
\par
We forward that leveraging container-based virtualisation can strongly reduce
continuous these integration impedances through the lightweight and portable affordances of containers. We demonstrate
that the alternative model of cluster management under containerisation offsets continuous
integration bottlenecks by supporting thousands of concurrent build executions.
Upon evaluating the application of fully-containerised CI workflows under existing CI systems 
we consider the successes and short comings of these approaches in the design of a purpose-built container-native
CI system. Subsequently, we contribute LibrumCI, a first-effort continuous integration system designed 
to support expansive integration loads of container-based projects. 

\end{abstract}

\keywords{continuous integration; Kubernetes; Jenkins; Docker; Cluster Management Frameworks; VCS; Agile}

\section{Introduction}
With organisational structures diversifying to off-shore, insource and outsource
development needs, software is increasingly being developed by fully- or 
partially-distributed teams. The contributions from team members must, at a minimum, be first validated
under a test infrastructure that is automated and robust enough to allow for
high levels of code churn. This development requirement is reflected in 
in the sustained and growing adoption of continuous integration (CI) practices in open-source and enterprise software projects \citep{Duvall, Fitz, Vas}. Traditionally most software projects have been characterised as having
poor integration practices. More often than often not a siloed team 
will conduct all development activities, arguably over a lengthy period,
and defer acceptance testing and code integration. Importantly, during
this period one can assert that the software is in an inoperative state, as there has
been no motivation to actually run the software and use it in a
production-like environment.
\par 
\citet{Jez} argue that many projects ``schedule lengthy integration phases at
the end of development to allow the development team time to get the branches
merged and the application working so it can be acceptance-tested". More concerning
is that when some projects arrive at this point ``their software is not fit for
purpose". These long-winded and challenging phases, commonly referred
to as ``integration hell", pose difficulties for the engineers working through the integration
and too for the leads and managers estimating the project delivery.
Applications of continuous integration practices have been found to effectively 
remove these phases at source \citep{Vas, Fitz, Jez, Duvall}. As a practice, CI seeks to reduce software deployment lead time by
facilitating frequent code churn through verifying contributions with automated 
builds and tests on production-like environments. \citet{Jez} advise that a team member integrate their work at least once daily, an effective undertaking of this process will mean that the software is always in a working state. 
\par
Effectively implementing a CI process first requires an extensive configuration
management strategy and versioning approach wherein all sources
and configurations are managed and tracked under version control. Thereafter,
the processes of provisioning, environment configuration, building, testing and code integration
can all be automated. Given that continuous integration environments involve
teams sharing remote resources, workflows can easily 
be impeded as integration demand increases. Integrations can be similarly
hampered as the complexity and configuration of the software changes.
In practice many CI pipelines consists of two types execution environments:
production-like (staging) environments for acceptance and system testing; and minimal 
environments for unit and functional testing. 
\par
To not hinder CI workflows staging environments need to be automatically 
reprovisioned and reconfigured to respect any environmental changes made by team members.
Doing so using VM-based virtualisation is generally quite cumbersome and expensive \citep{Gambi}.
These constraints also proceed effectively supporting elastic continuous integration environments.
We argue that leveraging container-based virtualisation can strongly reduce
continuous integration impedances around environment provisioning and configuration
through the lightweight and portable affordances of containers. Additionally, we demonstrate
that the alternative model of cluster management under containerisation offsets continuous
integration bottlenecks by supporting up to thousands of concurrent build executions.
Upon evaluating the application of fully-containerised CI workflows under existing CI systems 
we consider the successes and short comings of these approaches in the design of a purpose-built container-native
CI system. Subsequently, we contribute LibrumCI, a first-effort continuous integration system designed 
to support expansive integration loads of container-based projects. 
%
%This paper describes...high-level contribution
%
%The paper makes two contributions...exact contributions
%
%The next section presents foo. Section 3 bar. Section 4 baz.
%Finally, Section 6 offers some concluding remarks.

\section{Related Work}
Early studies around container-based virtualisation techniques
proceed with the proposal of resource containers \citep{Banga} and security
jails \citep{Kamp}.  With Linux V-Server becoming the first notable system providing
container virtualisation at operating system level, \citet{Soltesz} provides a comprehensive comparative 
study on the qualitative benefits of containers. Some years later
came research involving Docker-based containers and their inherent capability of effectively
reproducing research environments \citep{Boettiger}, which is particularly identical to software provisioning 
and configuring management. Later performance-specific comparative studies were also conducted 
using Docker \citep{Agarwal}.
\par
Subsequent works around containerised clouds note 
the facets of clustering and managing distributed containers \citep{Claus, Verma}, container 
cluster management frameworks are also highlighted. 
Expectedly, over the last two years many books targeted at practitioners have also been  
published, highlighting the nuances and benefits of containerised cluster management
\citep{db, holla, Rensin, Brewer}. No works yet exist around
leveraging container-based virtualisation in continuous integration environments.  

\section{Background}
\subsection{Continuous Integration}
Practices resembling continuous integration could be said
to stem as far back as the original lean manufacturing method. 
Nevertheless in software
engineering the practice was codified by \citet{Beck} 
as a core tenant of the Extreme Programming (XP) method.
Following, CI was also included in the Agile Manifesto as an encouraged
quality assurance practice. Amidst its wide adoption and popularity however, 
there is some variability in how teams are employing the practice, resulting 
is some debate as to exactly which integration activities one should follow \citep{Stahl}.
Nevertheless, at its core, CI forwards several central principles and high-level activities.

\subsubsection{CI Activities}
Before implementing CI a process for a given project, all software source code
and assets must be captured under a version control system (e.g. Git, SVN or Mercurial).
Such a system manages file changes using a controlled access repository. Importantly,
this provides the mechanism for developers to persist and maintain a mainline branch of the working software 
(e.g. the head or trunk branch), this is where any desired contributions are to be frequently 
integrated/merged \citep{Vas}. Version control systems also support reverting back to
previous revisions of the software, which is commonly availed of in CI. 
\par
Central to CI is the mechanism in which integrations are built, tested and fed back to the team. 
More often than not an automated CI system will manage these tasks. Today existing systems
are available as either hosted services or standalone setups \citep{Gous}, and there are
a multitude of such offerings in both the open-source and commercial spaces. 
The most notable of which are Jenkins, TravisCI, CruiseControl, CircleCI and Bamboo. 
As we will later explore, these systems offer varying approaches to how one configures and
defines a build pipeline, nevertheless on an integration build machine or cluster the following workflow generally occurs:
\begin{itemize}  
\item the CI server will poll, or listen to, contributions 
made against the version control repository.
\item upon receiving a contribution, the CI 
server will retrieve the source files and subsequently run build and tests scripts. 
\item the following build results are most commonly made available through a web interface and possibly
email.
\item the built application package, such as a WAR or EXE file, is also made available \citep{Stahl}.
\end{itemize}
\par
Continuously integrating reduces software project risk through 
the preventative deciton of defects by in turn reducing quality 
assumptions, and by eliminating manual repetitive integration
processes ``time, costs and effort" can be saved \citep{Vas}.
CI also affords the software being in a deployable state at any time \citep{Jez}.
Indeed, as a process CI is quite arguably beneficial, nevertheless challenges 
do exist around implementing a robust CI system 
and encompassing process.

\subsubsection{CI Challenges}
Employing an effective configuration management strategy is perhaps one of the
most challenging aspects of CI. It involves ensuring that every application-level configuration
needed per build phase (e.g. build, deploy and test) is captured and managed under one's
version control system. The same is required for the configurations around one's entire
production infrastructure, from the patch-level of an operating system (OS)
to the configuration files of databases and load-balancers. Furthermore, all of 
the dependencies between artefacts should also be expressed. \cite{Jez}
define this as ``the process by which all artefacts relevant to
your project, and the relationships between them, are stored, retrieved, uniquely
identified, and modified". Codifying the entire state of an infrastructure in
version control is certainly not trivial for most projects, particularly for non-greenfield projects.
\par
\cite{Jez} argue that a successful configuration strategy requires a ``holistic approach to 
managing all infrastructure". This involves the ``desired state", or current configuration, of 
one's infrastructure being tracked under version control. A major benefit of keeping
absolutely everything in version control is that source 
changes made at any level will trigger a CI build, which is in turn integrated, tested and deployable. 
That includes DBAs updating SQL scripts and operations members changing firewall 
rules. However, supporting this requires implementing automated infrastructure provisioning.
For instance, bumping the OS version which serves the application software
must trigger a CI build, but first this must cause 
the OS to be re-provisioned on the CI server and the rest of the downward dependencies 
to be rebuilt (e.g. OS libraries, middleware, application build script).  Tools like Chef, Puppet 
and Ansible are established automation tools in this space however, as we will later discuss, 
we argue that such heavyweight solutions are less well placed in modern CI practices.
\par
True for both hosted services and standalone setups, powerful servers or build farms usually 
underly a CI system to ensure that build-times are as a quick as possible \citep{Campos}. As a consequence,
these shared remote resources ``become a bottleneck when the number
of developers increases" as more concurrent builds can occur \citep{Gambi}. Several practices have
been adopted to alleviate these limitations. One addresses this horizontally through the ``componentisation of larger
applications", wherein a codebase is divided into well-defined parts that are developed 
and integrated separately. Thus, resulting in separate CI builds for each component \citep{Jez}.
Other approaches emphasise on test selection. For instance, those tests related to the changes made in a given contribution
are ran first (``pre-submit"), and if successful the integration is made, then the remaining tests are executed (``post-submit") and if a failure occurs the integration is rolled back \citep{Elbaum}.


\subsubsection{CI in Practice}
Industry studies have found that 57\% of companies are employing
CI on a daily or weekly basis\footnote{\href{http://info.thoughtworks.com/rs/thoughtworks2/images/Continuous\%20Delivery\%20_\%20A\%20Maturity\%20Assessment\%20ModelFINAL.pdf}{http://info.thoughtworks.com/rs/thoughtworks2/images/\\Continuous\%20Delivery\%20_\%20A\%20\\Maturity\%20Assessment\%20ModelFINAL.pdf}}, however there is a clear disparity in how those
practitioners are actually implementing the process. \citet{Stahl} have revealed that there are several disagreements in the existing research around how CI is actually practiced in industry. 
\par
CI has also become a well adopted practice in open-source projects,
particularly for those projects (75\%) hosted on GitHub. Those surveyed 
integrators have been found to use ``few quality evaluation tools other than
continuous integration" in their integration workflows \citep{Gous}. 
In the case of GitHub hosted projects, 
TravisCI is currently the most popular tool \citep{Yu}. Similar to many other
modern hosted CI solutions, a repository is primarily configured 
with the system through a repository-level YAML file that declares the entire build workflow  \citep{Santos}.
This file includes the infrastructural configuration (e.g. host OS type, host OS version, middleware dependancies), the application-level configuration, and finally the build and test scripts to be ran. The following \texttt{.travis-ci.yml} file is quite
similar to that used on the Ruby on Rails project:
\begin{minted}[
    frame=single
  ]{yaml}
# use a Linux image with Ruby pre-installed
os: linux 
language: ruby
sudo: false

cache:
  bundler: true
  directories:
    - # between builds cache installed `bundler' 
    - # packages (gems) and any other directories
before_install:
  - # before starting services and add-ons fetch
  - # and configure other system and/or 
  - # middleware dependancies
# ensure services are running and available 
# over the network
services:
  - memcached
  - redis
  - rabbitmq
addons: # use beta services
  postgresql: ``9.4"
before_script:
  - # before running tests run some commands 
  - # like (re)configuring the application
script: 
  - ci/run_tests.rb # test script to run
  - ci/run_inter.rb # integration script to run
# use each Ruby versions against the test script
rvm:
- 2.2.5
- ruby-head
# run the test script again under each specified 
# environment variable 
env:
  matrix:
    - `SOME_FLAG=0'
    - `SOME_FLAG=1'
notifications:
  - # send builds statuses to IRC
  \end{minted}
\par
Upon receiving a contribution, such a service will provision
and build a virtual environment based on the repository's CI configuration
file, cache those whitelisted directories for subsequent builds, then and run any
specified scripts or commands (which are generally for testing and integrating).
Most services offer a web interface wherein build statuses and be observed, and 
integrations with other tools for notifying build statuses. As you would expect,
a build failure occurs when a provisioning-, test- or integration-related command
terminates unsuccessfully. 
\par
In theory, for most commercial software projects it is impossible to
employ a mature CI process under such tools. The execution environments offered by such services are generally limiting. 
For instance, TravisCI supports  only three virtual environments for build execution: Ubuntu 12.04,
OS X Mavericks and Ubuntu 14.04. CI under these constraints may be
adequate for software projects that only rely on unit- and functional- level
testing. However, as we will later explore, more complex ``n-tierd" applications require build pipelines that 
include acceptance testing on an environment akin to production. 
\par
Standalone setup CI systems offer greater flexibility around build 
execution environments. \citet{Duvall} forwards several tools such
as CruiseControl, Apache Continuum, IBM's UrbanCode Deploy and Draco.NET 
as potential standalone solutions. In Jenkins, also a popular open-source contender in this space, 
one can define build pipelines comprised of one or more phases, and each of which can be executed on a different  
execution environment \citep{Smart}. For instance, one might manually provision and configure a 
minimal compute environment for unit- and functional-level testing and a more production-like 
one for acceptance testing. Having installed and configured Jenkins on those machines, one could then
configure the given repository and define the pipeline via the Jenkins UI.
Tools such as Jenkins can also be extended to leverage cloud features. For instance,
the Amazon EC2 Plugin, Azure Slave Plugin allow one to dynamically
provision compute resources in a distributed master/slave Jenkins setup \citep{Smart}.

\subsection{Containerisation}
Selecting appropriate automation tools
generally comes down to what is ``best fit for your
environment and development process". \citet{Duvall}
argues that this includes the functionality, reliability, longevity and 
usability of the given tool. All too often these
evaluations ``often transcend the practical and 
escalate into what sounds like a religious debate". 
As we will subsequently explore, recently established 
standards and technologies in containerisation 
afford significant opportunities to CI.

\subsubsection{Establishing the Container Standard}
Containerisation is a recently resurged computing paradigm that is
having a significant impact on how applications are being built,
shipped and ran. Along with being less resource intensive and
more portable, containers simplify dependency management, application
versioning and service scaling, as opposed to deploying
applications or application components directly onto a host operating
system. Docker, albeit a relatively young project, has successfully
established a container standard.
\par
Containers have a long history in computing though much of their recent popularity 
surround the recent developments of both LXC and the Docker platform. 
The former can be described as a container execution environment,
or more formally, a Linux user space interface to 
access new kernel capabilities of achieving process isolation through namespaces
and cgroups \citep{Claus}. The latter is an open-source suite of tools managed by Docker Inc.\ which
extends upon container technology such as LXC, in turn 
allowing containers to behave like ``full-blown hosts in their own right" 
whereby containers have ``strong isolation, their own network and storage stacks, as well 
as resource management capabilities to allow friendly co-existence of multiple containers on a host" \citep{db}.
\par 
Uncertainties around Docker's maturity and production-readiness have been expressed \citep{Kereki, Powers, Merkel}, however 
over the last two years the states of both Docker and the containerisation ecosystem continue to rapidly progress.\
Last year Docker has seen an unprecedented increase in development, adoption and community uptake \citep{Merkel}. Most
notably was the introduction of customisable container execution environments. This means as opposed to LXC one can
``take advantage of the numerous isolation tools available" such as ``OpenVZ, systemd-nspawn, libvirt-sandbox, qemu/kvm, BSD Jails and Solaris Zones".
Also included in this 0.9 release was the new built-in container execution driver ``libcontainer", which replaced LXC as the default driver.
Going forward on all platforms Docker can now execute kernel features such as ``namespaces, control groups, capabilities, apparmor profiles, 
network interfaces and firewalling rules" predictably ``without depending on LXC" as an external dependency \citep{Hykes}. 
\par
Interestingly, libcontainer itself was the first project to provide a standard interface for making containers and managing their lifecycle.\
Subsequently the Docker CEO  announced the coming together of industry leaders and others in partnership with the Linux Foundation
to form a ``minimalist, non-profit, openly governed project" named The Open Container Initiative (OCI), with the purpose of defining 
``common specifications around container format and runtime" \citep{Golub}. 
Thereafter Docker donated its base container format and runtime, libcontainer, to be maintained by the OCI. Docker Engine and Rocket (by CoreOS) are both
container runtimes which adhere to these standards. 

\subsubsection{Applicability of Containers in CI}
In terms of the configuration and provisioning of execution environments, containers  
offer a much a more lightweight and portable alternative to that of the traditional VM-based approach.
Both approaches are ``virtualisation
techniques, but solve different problems". A container-based ecosystem lends itself better 
towards the ``packaging, delivering and orchestrating" of execution environments, having
a more PaaS focus. Whereas VMs emphasise more on ``hardware allocation and management",
having a more IaaS foucs \citep{Claus}. Consequently, both approaches bear
``significant qualitative differences". Most notably, the ``start-up time of a full container is 6x lower than a
VM, and memory footprint is 11x lower than a VM" \citep{Agarwal}.
\par
With respect to VM-based environments, the container image standard established and implemented by Docker affords 
further qualitative advantages, particularly around the area of configuring execution environments.   
For a given software application or component, Docker allows
one codify most of all potential environmental configuration
into one manifest or declaration, a \texttt{Dockerfile}. Apart from the
hardware resource requirements of the application (cpu, memory and disk), 
herein one can capture all system- and application- level configurations. Thus,
from the perspective of a CI system, a  \texttt{Dockerfile} can
act as an all encompassing build manifest. Consider that, 
for unit and functional testing only, we require a build execution environment
for a NodeJS application running on Ubuntu Xenial, where ``\texttt{runTests.sh *}" executes our test suites.
Such a \texttt{Dockerfile} would be as follows:
\begin{minted}[
    frame=single
  ]{docker}
# base from a clean Ubuntu Xenial image
FROM ubuntu:16.04
# set static build configurations
ENV NPM_CONFIG_LOGLEVEL info
ENV NODE_ENV test
# fetch and install build/runtime dependancies
RUN apt-get update
RUN apt-get install -y apt-utils curl git
RUN curl -sL deb.nodesource.com/setup_6.x \
  | bash -
RUN apt-get install -y nodejs 
RUN rm -rf /var/lib/apt/lists/* \
  && apt-get purge -y --auto-remove apt-utils curl
# specify forwarded container ports to the host
EXPOSE 8080
# create, and cd into, a HOME directory
WORKDIR /app
# cp local sources into the image
COPY ./myLocalApp/ /app/
# cp local app configuration into the image
COPY ./config-test.conf /app/
# install application dependancies
RUN npm install
# specify entrypoint for running the container 
ENTRYPOINT ["/app/runTests.sh"]
# specify default arguments for the entrypoint
CMD ["*"]
\end{minted}
\par
In terms of CI, perhaps one of the greatest benefits that is afforded here is 
Docker's distributed and opportunistic caching mechanism for builds.
Firstly, it is important to note that a built container manifest, an \textit{image}, is just a stateless filesystem that acts
as a parameter to a container runtime. Thus, a \textit{container} is an running instance of an \textit{image}.
An image begins with a replica of a root filesystem (defined in a \texttt{Dockerfile} with the \texttt{FROM} instruction).
Following, through leveraging ``layered and versioning
copy-on-write filesystems (AuFS or btrfs)", the termination of
all subsequently defined instructions create additional image \textit{layers}, and references to each are
stored for caching alongside their respective filesystem \citep{Arndt}. Thus, for example,
if a host machine is building our example image for the first time, and has not previously
built  \texttt{ubuntu:16.04}, then all instructions in the file will be terminated and cached.
If we are rebuilding the image, and have only modified the \texttt{config-test.conf} source, 
the respective \texttt{COPY} layer for that source with all subsequent layers become invalidated and then rebuilt.

\section{Evaluation and Design}
We evaluate in detail some applications of containerisation with existing CI systems, and subsequently forward the design
and implementation of our first-effort fully-containerised continuous integration system. To fully avail of the advantages of containerisation we argue that the entirety of CI systems should be capable running under container-based virtualisation. Hence, the system and its runtime components being containerised, including the individual executions of its CI builds. Thus, the specific scope of our evaluation is to measure the effectiveness of existing systems running containerised builds while being ran themselves as containers. As previously highlighted, CI system
offerings are either generally either hosted services or standalone setups. With the exception of TravisCI and some other 
less notable systems, most hosted services are proprietary. TravisCI is foremost a hosted service but also supports standalone deployments.
GoCD\footnote{\href{http://martinfowler.com/articles/go-interview.html}{http://martinfowler.com/articles/go-interview.html}} is a somewhat lesser known system, but perhaps only because it is the recent predecessor of CruiseControl, that too supports standalone deployments.
Thus, we consider both TravisCI, Jenkins and GoCD for our evaluations.
\par
As previously highlighted, scalable and robust CI systems are 
predicated by their ability to facilitate high-levels of code churn. That is,
being capable of handling increasing numbers of contributions while 
sustaining build throughput. A container-native CI system is the first 
steps toward this path. By running and managing the system itself and all of its generated 
build executions through containers we can utilise less resources. 
Unfortunately, both TravisCI and GoCD do not fully support all of their components 
being ran as containers. For TravisCI\footnote{\href{https://enterprise.travis-ci.com/docs#host-machines}{https://enterprise.travis-ci.com/docs#host-machinesl}} 
and similar for GoCD, one or more Docker worker hosts can run all ``tests/jobs in isolated containers", 
however it does require its master and related services being hosted on a VM-based machine.
Fortunately, Extensions exist for running Jenkins under a multi-container setup\footnote{\href{https://www.docker.com/sites/default/files/UseCase/RA_CI\%20with\%20Docker_08.25.2015.pdf}{https://www.docker.com/sites/default/files/UseCase/\\RA_CI\%20with\%20Docker_08.25.2015.pdf}}, i.e.
one master Jenkins container and \textit{n} amount slave containers.


\subsection{Fully-Containerised Single-Host Jenkins}
Given a single Docker host we evaluate a fully-containerised Jenkins 
distributed master/slave Jenkins setup. That is, on one container-based
host machine we run a container master container and one or more slave containers,
which themselves run the execution environments for builds as separate containers. 
We expect the aforementioned qualitative container benefits from running the involved static 
containers (master/slave) in this set up, however as we will demonstrate 
there are several approaches and considerations to be made when creating and managing
dynamic and ephemeral containers.
\par
We first consider the approach of running an internal Docker daemon within
each slave container. Running the master and slave containers is straightforward. 
Jenkins slave agents can be registered with a master using either Java Web Start (JNLP) or SSH.
Given our Unix-based environment, we favour SSH and generated key-pair. This can be 
achieved by extending the base Jenkins master image with a custom Dockerfile or 
by manually generating the keys through a command on the running container. 
We can then define a custom slave image which installs the special purpose (Docker-in-)Docker 
Engine as follows:
\begin{minted}[
    frame=single
  ]{docker}
# base from latest Jenkins-slave image
FROM jenkinsci/ssh-slave
# fetch the Docker(-in-Docker) Engine
RUN wget "https://raw.githubusercontent.com\
  /docker/docker/\
  3b5fac462d21ca164b3778647420016315289034\
  /hack/dind" -O /usr/local/bin/docker \
  && chmod +x /usr/local/bin/docker
# expose ssh port for master
EXPOSE 22
# capture the ssh public key shared with master
ENV JENKINS_SLAVE_SSH_PUBKEY ssh-rsa AAAABccc123
\end{minted}	
A typical container is not allowed to access any host devices,
however as our slave containers run their own Docker daemons they will need to be permitted access. 
Such is achieved by running the slaves with a ``privileged" flag. Given we run \textit{n} amount of slave instances
with this flag, we can then begin configuring repositories and pipelines via the
Jenkins master UI. Notwithstanding the system only having the compute resources of a single machine, 
we can see in figure~\ref{fig:jenkins-1} that there are some inefficiencies to this nested containerisation
approach.
\begin{figure}[htp]
      \centering
      \includegraphics[width=8.6cm,height=5.3cm]{jenkins-1}
      \caption{Single-host Distributed Jenkins with Nested Build Containers} 
      \label{fig:jenkins-1}
\end{figure}
\par
The outer Docker daemon on the host machine will allow
for layer-sharing between the master (jenkins-master) and the slave
containers (jenkins-slave-docker-\textit{n}). For instance,
both images depend up open-JDK-7 so once the master image
has fetched the layer it is cached for any subsequently built slaves.
Importantly, the inner-daemon of slaves is not shared, and this is 
particularly inefficient if we wish to make all slave containers ephemeral as
their cache would be eliminated once removed (i.e. only provisioning slaves when required and removing them afterward). 
\par
Docker clients issuing \textit{build} or \textit{run} commands do so
against the default daemon process which lives as a UNIX domain socket 
(\textit{/var/run/docker.sock}). We can reduce these some of the 
shortcomings of our current approach by sharing this socket with the
slave containers. The builds they create via the Docker client in turn
become sibling containers that avail of the same cache.
It is important to note that this is not a thorough solution,
the daemon itself is a highly privileged process on the host machine.
Sharing it with other processes has security implications.
Notwithstanding this, in our slave image we instead install the standard
Docker Engine to use the client API commands within CI builds.
\begin{minted}[
    frame=single
  ]{docker}
  		....
# fetch docker engine and don't run the daemon
RUN set -ex\
  && apt-get install apt-transport-https\ 
  ca-certificates\
  && apt-key adv --keyserver\ 
  hkp://p80.pool.sks-keyservers.net:80\
   --recv-keys\
  58118E89F3A912897C070ADBF76221572C52609D\
  && echo "deb https://apt.dockerproject.org/repo\
  debian-jessie main" > \
  /etc/apt/sources.list.d/docker.list \
  && apt-get update \
  && apt-get install docker-engine
		....
\end{minted}	
\begin{figure}[htp]
      \centering
      \includegraphics[width=8.6cm,height=5.3cm]{jenkins-2}
      \caption{Single-host Distributed Jenkins with Sibling Build Containers} 
      \label{fig:jenkins-2}
\end{figure}

\subsection{Fully-Containerised Multi-Host Jenkins}
Compared to a VM-based approach, containers are inherently superior at scale.
Containerisation is a lightweight virtualisation technique, best designed for 
the swift provisioning of execution units that are ``short-lived and fragile".
Thus, as opposed to being concerned with provisioning and configuration management,
containers at scale instead require an emphasis on orchestration to ``run efficiently
and resiliently" \citep{Rensin}. Furthermore, containers running on multi-host environments
have different scheduling concerns to that of VMs. Consider that multiple containers can run
on one host, to best utilise resources new containers will need to be scheduled on the most appropriate
host. We demonstrate this differing model of cluster management through evaluating fully-containerised multi-host Jenkins 
solutions.
\par
Consider distributing our sibling-container Jenkins solution across multiple machines.
In addition to the master node, we must provision \textit{n} amount of slave-dedicated host machines. 
Jenkins supports executing only one concurrent job per slave agent \citep{Smart}. Thus, given that \(n\) is the number
of slave container on a host, we afford for the system scheduling \(n+1\) containers per host. Henceforth, 
dependant on compute capacity of each host we determine how many Jenkins slave containers we will run on each. 
Finally,  we can configure the running slaves to discover the master and begin configuring repositories for CI via the UI. 
\par 
Such a distributed solution
affords build load to be spread reasonably effectively but utilises resources somewhat poorly while incurring notable bottlenecks.
As a Docker daemon runs on a per-host basis, only slaves running on the same host will share the same
build cache. Ideally any previously built layers should be cached for use across the entire cluster.
Furthermore, the approach for orchestrating slave containers
is manual and the mechanism for scheduling their respective CI build containers is static (as they will always
be scheduled on the same host even if it is overcapacity).
\par
Our sibling build containers already have their own orchestration instructions. Upon receiving a CI contribution a 
slave-agent will use its Docker client to \textit{build}, \textit{run} and then \textit{remove} the respective test container.
To utilise resources more effectively we would also like the slave-agent containers themselves to be orchestrated and ephemeral. 
A community plugin\footnote{\href{https://wiki.jenkins-ci.org/display/JENKINS/Docker+Plugin}{https://wiki.jenkins-ci.org/display/JENKINS/\\Docker+Plugin}} exists 
for Jenkins which allows for slave containers to be orchestrated per CI contribution received. Upon the respective 
build job finishing it will then remove the that slave container. Notably, this approach lends itself somewhat better to
the model of container cluster management, orchestrating containers over any ahead-of-time provisioning and configuration.
Nevertheless, this plugin has no scheduling capabilities. Such is unsurprising considering that viewing host resource consumption 
is a privileged action. Since the Jenkins system runs as containers it cannot look outward and introspect the host.

\subsection{Cluster Management: Kubernetes}
Container cluster management frameworks transparently govern the
scheduling, orchestration and isolation of containers \citep{Rensin}. 
Such frameworks allow one ``view a set of hosts as a 
unified programmable reliable cluster" \citep{goasguen}, and generally all cluster nodes
will use a shared Docker daemon. We continue our evaluation by
considering how the integration of such tools might deliver a more optimal multi-host
Jenkins CI system.
\par
Practitioners and industry experts note that the cluster management tools supporting Docker
vary greatly in terms of capability, architecture and target cluster proportion
\citep{goasguen, holla}. Swarm is the native cluster management solution for 
Docker, and is comparatively lighter-weight than other tools in this space \citep{holla}.
For instance, by default Swarm is actually not distributed or highly available. 
Through configuring a supported discovery backend, such
as Consul or ZooKeeper, Swarm nodes can then be added to 
the cluster and a fail-over master node can be then provisioned and configured.
\par
Standalone Swarm may be a fitting clustering solution for some use-cases, however supporting
cluster sizes from a hundred to thousands of nodes requires a more production-grade 
cluster platform such as Apache Mesos or Kubernetes. 
The former is foremost a ``data center resource allocation system" with an 
interchangeable interface for accessing and scheduling cluster resources. 
The later is a higher-level platform specifically 
designed for managing containerised applications across multiple hosts including programmable mechanisms for container orchestration, scaling and monitoring  \citep{goasguen}.
Thus, we discount Swarm and Mesos from our evaluation and consider distributed
Jenkins CI in conjunction with Kubernetes. 
\par
Kubernetes (k8s) is a production-grade container management 
system that was originally built, and subsequently open-sourced, by Google.
It builds upon a decade of lessons learned from the design and use of Borg, 
an internal tool that manages virtually all of Google's cluster workloads \citep{Rensin}.
As illustrated in figure~\ref{fig:jenkins-3}, we have implemented a distributed
Jenkins CI system which supports full-containerised builds using 
our sibling build container approach. Before we evaluate the effectiveness
of this CI system let us first detail the underlying Kubernetes cluster architecture
and its primary components.
\begin{figure}[htp]
      \centering
      \includegraphics[width=8.75cm,height=6.2cm]{jenkins-3}
      \caption{Distributed Jenkins under Kuberentes} 
      \label{fig:jenkins-3}
\end{figure}
\par
The k8s master node serves as the kernel of the cluster.
Its runs administrative and regulatory services as containers 
such as ones for: cluster-user admin control (policy-controller); cluster network 
management (Flannel and kube-proxy); 
container scheduling (kube-scheduler); an API for cluster object manipulation (kube-apiserver);
grouped container management  (kube-controller-manager); and a cluster UI \citep{Verma}. 
Worker nodes must be provisioned with some
agent-containers which communicate back to those service containers
on the master node. The most notable of such required agents is the kubelet daemon,
which is primarily responsible for responding ``to commands from the master
to create, destroy, and monitor the containers on that host".
\par
Under a bare Docker setup, the expressions for inter-container relationships, 
container port-forwarding rules and
container volume mounts are only definable as arguments as to the Docker \textit{run}
API. In k8s, Pods are the base mechanism for expressing these configurations and running one or containers.
They act as a ``resource envelope for one or more containers that are always
scheduled onto the same machine and can share resources" \citep{Verma}.
In terms of deploying long-running containers, pods may not be the appropriate
k8s object of choice. Due possible changes in the overall cluster health 
``the master scheduler may choose to evict a pod from its host" and
spin up a new instance on another node \citep{Rensin}. Higher-level k8s objects 
such as deployments and replication controllers should be for favoured when
maintaining the state of long-running pods.
\par
Revisiting our evaluation, we orchestrate and manage
our \textit{jenkins-master} pod via a deployment object. This allows us provide
declarative updates to the running pod such as changing the version of Jenkins master image used or
allocating more memory its container. Via the Jenkins UI we then configure the Jenkins k8s plugin\footnote{\href{https://wiki.jenkins-ci.org/display/JENKINS/Kubernetes+Plugin}{https://wiki.jenkins-ci.org/display/JENKINS/\\Kubernetes+Plugin}}
to use our custom slave image when dynamically creating \textit{jenkis-slave} pods. 
This means that the respective build execution envoirnments for slave pods will be in the form of sibling-containers. 
\par
Upon receiving CI contributions Jenkins will request a \textit{jenkis-slave} pod from the k8s API via HTTP. 
Thus, in conjunction kubelet with the k8s master will schedule that slave pod where most appropriate. 
With respect to our previously evaluated solutions this affords much greater resource utilisation as 
slave container orchestration and scheduling concerns are managed fully by k8s.
Notwithstanding these gains this approach is inherently flawed.
This is principally because k8s ``schedules and
orchestrates things at the pod level, not the container level" \citep{Rensin}. Our
slave pods simply use the native
Docker API to build and run their corresponding sibling-build on that host. 
Most importantly, this means that these containers are not actually scheduled or managed
by k8s.

\subsection{LibrumCI}
We forward the implementation of a first-effort CI system that
effectively supports fully-containerised CI workflows
through leveraging the native features of cluster 
management frameworks. Our evaluation of employing
fully-containerised CI workflows with existing CI systems
demonstrates the discordance in containerising applications originally architected for 
VM-based environments. Containerising software
requires ``thinking in terms of services instead
of applications". Traditional CI systems such as Jenkins
we not developed under these terms.
\par 
Consider the Jenkins master image, as a single UNIX process
it is responsible for serving a front-end, user account management,
system authentication, resource authorisation, build queuing, 
serving an API for resource manipulation
and so on. Most importantly, it persists all of its state internally on disk (in \textit{/var/lib/jenkins} by default).
As this process is stateful Jenkins master cannot be horizontally scaled. Furthermore,
this monolithic design prohibits the scaling of individual segments of the application. 
\par
Additionally, our evaluations have revealed that effectively
applying fully-containerised CI workflows in such tools through 
cluster management frameworks is challenging. Our approach
of using Jenkins sibling-container-builds in k8s contravenes 
and circumvents the intended use of the framework in how one is to 
schedule containers and use node resources. To avail of 
the k8s orchestration and scheduling features all
CI builds must be executed in pod form. One might note that
k8s only supports building and running images that have been pushed
to a registry. Thus, on a Jenkins slave we cannot dynamically create 
build pods based off the \textit{Dockerfile} of a given CI contribution.
\begin{figure}[htp]
      \centering
      \includegraphics[width=8.75cm,height=8.2cm]{librum}
      \caption{LibrumCI running concurrent CI builds} 
      \label{fig:librum}
\end{figure}
\par
These observations have been applied to the design of LibrumCI. As illustrated in figure~\ref{fig:librum}
we have adopted a micro-service architecture to allow for the 
scaling of individual components in the system. On a high-level
the system is simply comprised three notable long-running services (Mongo, Githooks
and Master) which coordinate together to dynamically schedule a build pipeline. A
given pipeline can be comprised of up to three build-phases. Each of which
occur sequentially in the form of an ephemeral, or ``sidecar", pod. All of the system services
are as follows:
\begin{itemize}  
\item \textbf{Front-end web-service} is a single-page-application client of the LibrumCI Master API. It provides an interface for creating and configuring repositories, and for viewing repository build pipelines including their per build-phase log output.  
\item \textbf{Mongo database service} persists 'Repo', 'Branch' and 'Build' entity documents that are utilised by the Githooks and Master web-services.
\item \textbf{Githooks web-service} is responsible for listening to Github push events (contributions). Upon receiving a contribution from a preconfigured repository, it will persist the contribution data (commit SHA, branch name, etc.), create a new build record and then request that the given build be scheduled via the LibrumCI Master API.
\item \textbf{Master web-service} serves the RESTful API for resources and includes a schedule endpoint for build entities. This endpoint uses the k8s API to sequentially schedule the build phase sidecar pods. Using the k8s API each of these running pods will be streamed, where the phase status and logs are captured and persisted for the end user.
\item \textbf{Network File System server} permits the same persistent volume (/repos/) being handed off between build phase pods, allowing for multiple simultaneous writers to that volume. On one external disk all configured repository files are name-spaced under this /repos/ volume. Thus, our NFS server allows build phases concurrently attach to the volume to synchronise and read repository files.
\item \textbf{git-sync sidecars} synchronise
the repository belonging to the incoming contribution by fetching it from the given commit SHA into
persistent file storage (/repos/).
\item \textbf{image-sync sidecars} synchronise the respective image of the incoming contribution by building the \textit{Dockerfile} with Docker Engine, if this was successful
the image (build artefact) is pushed to a registry. The registry address and password is preconfigured on the system-level.
\item \textbf{test-runner sidecars} use the pushed image of the contribution to run the build tests. The command to run these tests is preconfigured on the repository-level.
\end{itemize}
%Jenkins and GoCD are designed to run, and communicate the status of, 
%respective CI builds 

%A Kubernetes cluster does not manage a
%fleet of applications. It manages a cluster of services. You might run
%an application (often your web browser) that communicates with
%these services, but the two concepts should not be confused.
%A service running in a container managed by Kubernetes is
%designed to do a very small number of discrete things. As you design
%your overall system, you should keep that in mind. I?ve seen a lot of
%well meaning websites fall over because they made their services do
%too much. That stems from not keeping this distinction in mind
%when they designed things.
%If your services are small and of limited purpose, then they can
%more easily be scheduled and re-arranged as your load demands.
%Otherwise, the dependencies become too much to manage and
%either your scale or your stability suffers.
%At this point you might be thinking that things would be easier if
%you just ran processes that need to talk to each other in the same
%container.
%You can do it, but I really wouldn?t. It?s a bad idea.
%If you do, you undercut a lot of what Kubernetes has to offer. Specifically:
%1. Management Transparency?If you are running more than
%one process in a container, then you are responsible for monitoring
%and managing the resources each uses. It is entirely possible
%that one misbehaved process can starve the others within the
%container, and it will be up to you to detect and fix that. On the
%other hand, if you separate your logical units of work into separate
%containers, Kubernetes can manage that for you, which will
%make things easier to debug and fix.
%2. Deployment and Maintenance?Individual containers can be
%rebuilt and redeployed by you whenever you make a software
%change. That decoupling of deployment dependencies will make
%your development and testing faster. It also makes it super easy
%to rollback in case there?s a problem.
%3. Focus

%policy-rich, topology-aware, workload-specific function that significantly impacts availability, performance, and capacity. The scheduler needs to take into account individual and collective resource requirements, quality of service requirements, hardware/software/policy constraints, affinity and anti-affinity specifications, data locality, inter-workload interference, deadlines, and so on. Workload-specific requirements will be exposed through the API as necessary.

\section{Conclusions}
Our evaluations of the applicability of containerisation with continuous integration systems reveals 
particular shortcomings in the supports of fully-containerised continuous integration.
With the exception of commercial offerings, many CI tools do not yet meaningfully 
support containerised builds. This is particularly true when attempting to
implement fully-containerised CI pipelines with standalone CI systems
in distributed environment. 
\par
Due to the inherent differences between VM- and container-based virtualised,
cluster management concerns shift from provisioning and configuration management
to service orchestration and scheduling. This paradigm change becomes apparent 
when attempting to apply traditional clustering techniques to a fully-containerised CI system.
In evaluating the integration of Jenkins with Kubernetes we have found
challenges and limitations in running fully-containerised builds. To leverage 
container clustering frameworks such as Kubernetes we forwarded LibrumCI as part of this work.
Unlike existing CI systems, which have been designed independently of containers and cluster frameworks,
we explicitly architect LibrumCI to leverage the native capabilities of Kubernetes.



\vspace{-7.5mm}
\renewcommand{\refname}{\section{References}}
\bibliographystyle{IEEEtranN}
\bibliography{report}
\end{document}
